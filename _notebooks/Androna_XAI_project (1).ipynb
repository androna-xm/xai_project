{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Androna_XAI_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "Για τη δημιουργία του dataset επιλέχθηκαν 2 κλάσεις του places, ***kitchen*** και ***office***. Οι εικόνες του COCO dataset που αντιστοιχούν σε αυτές τις κλάσεις επιλέχθηκαν με βάση κατηγορίες αντικειμένων που περιέχουν. Συγκεκριμένα για την κλάση ***kitchen*** επιλέχθηκαν οι εικόνες που έχουν ως labels τις κατηγορίες ***refrigerator,sink,toaster,oven,microwave*** και αντίστοιχα για την κλάση ***office*** οι εικόνες με labels ***keyboard, laptop, mouse, cell phone, tv, book***. Για την κλάση *kitchen* συγκεντρώθηκαν 31 εικόνες ενώ για την κλάση *office* 62. "
      ],
      "metadata": {
        "id": "1U3xdzgnA2uQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsM-ZQ4ZQJjJ",
        "outputId": "7f4712a0-f68e-482f-dcf5-e4efdf74a8f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-24 19:47:07--  http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.217.45.36\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.217.45.36|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 252907541 (241M) [application/zip]\n",
            "Saving to: ‘annotations_trainval2017.zip’\n",
            "\n",
            "annotations_trainva 100%[===================>] 241.19M  98.3MB/s    in 2.5s    \n",
            "\n",
            "2022-07-24 19:47:10 (98.3 MB/s) - ‘annotations_trainval2017.zip’ saved [252907541/252907541]\n",
            "\n",
            "Archive:  annotations_trainval2017.zip\n",
            "  inflating: annotations/instances_train2017.json  \n",
            "  inflating: annotations/instances_val2017.json  \n",
            "  inflating: annotations/captions_train2017.json  \n",
            "  inflating: annotations/captions_val2017.json  \n",
            "  inflating: annotations/person_keypoints_train2017.json  \n",
            "  inflating: annotations/person_keypoints_val2017.json  \n",
            "loading annotations into memory...\n",
            "Done (t=22.41s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ],
      "source": [
        "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip # download dataset\n",
        "!unzip annotations_trainval2017.zip # unzip dataset\n",
        "from pycocotools.coco import COCO\n",
        "coco = COCO('annotations/instances_train2017.json')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " %matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import pylab\n",
        "import os\n",
        "pylab.rcParams['figure.figsize'] = (15.0, 17.0)\n",
        "import torch\n",
        "from torch.autograd import Variable as V\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms as trn\n",
        "from torch.nn import functional as F\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from skimage import io\n",
        "from IPython import display\n"
      ],
      "metadata": {
        "id": "1z6nm87aiwOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get all images containing given categories\n",
        "\n",
        "classes = {\n",
        "    'kitchen' : ['refrigerator','sink','toaster','oven','microwave'],\n",
        "    'office' : ['keyboard', 'laptop', 'mouse', 'cell phone','tv' , 'book']\n",
        "}\n",
        "catIds ={'kitchen': [], 'office': []}\n",
        "imgIds ={'kitchen': [], 'office': []}\n",
        "img = {'kitchen': [], 'office': []}\n",
        "for cat in ['kitchen','office']:\n",
        "  catIds[cat] = coco.getCatIds(catNms=classes[cat])\n",
        "  imgIds[cat] = coco.getImgIds(catIds = catIds[cat] )\n",
        "  img [cat]= coco.loadImgs(imgIds[cat]) #list [{coco_url,..,id,...},..]\n",
        "  print('The \"' + cat + '\" class has %d images' %len(img[cat]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi_9_SWLQ0RG",
        "outputId": "ae3716ea-5eac-4710-beff-93d6ee1c70bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The \"kitchen\" class has 31 images\n",
            "The \"office\" class has 62 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all anotations of an image \n",
        "\n",
        "anns_per_image = {'kitchen': {}, 'office':{}} # imgId --> label_ids=[], label_texts=[]\n",
        "for cat in ['kitchen','office']:\n",
        "\n",
        "  for imgId in imgIds[cat]:\n",
        "      ann_ids = set(coco.getAnnIds(imgIds = imgId, iscrowd=None))\n",
        "      anns = coco.loadAnns(ann_ids)\n",
        "      anns_per_image[cat][imgId]={\"label_ids\":ann_ids, \"label_texts\":[coco.loadCats(ann['category_id'])[0]['name'] for ann in anns] }\n",
        "\n"
      ],
      "metadata": {
        "id": "pDjeJ18zOsMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification / XAI\n",
        "Στο dataset των εικόνων που δημιουργήθηκε εφαρμόζουμε τον classifier του places, ο οποίος κατατάσσει τις εικόνες βάσει πιθανοτήτων σε κάποιες από τις κατηγορίες του. Για κάθε εικόνα παρουσιάζονται τα labels/annotations τα οποία διαθέτει από το COCO dataset, οι 5 πιο πιθανές κατηγορίες (scene categories) στις οποίες κατατάχθηκε από τον classifier καθώς και τα scene attributes της από το places. Εφαρμόζοντας το GradCam σημειώνονται οι περιοχές της εικόνας με τα χαρακτηριστικά που οδήγησαν στην πρόβλεψη που έκανε ο classifier. "
      ],
      "metadata": {
        "id": "0hY2WA3JE9-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PlacesCNN to predict the scene category, attribute, and class activation map in a single pass\n",
        "# by Bolei Zhou, sep 2, 2017\n",
        "\n",
        "def recursion_change_bn(module):\n",
        "    if isinstance(module, torch.nn.BatchNorm2d):\n",
        "        module.track_running_stats = 1\n",
        "    else:\n",
        "        for i, (name, module1) in enumerate(module._modules.items()):\n",
        "            module1 = recursion_change_bn(module1)\n",
        "    return module\n",
        "\n",
        "def load_labels():\n",
        "    # prepare all the labels\n",
        "    # scene category relevant\n",
        "    file_name_category = 'categories_places365.txt'\n",
        "    if not os.access(file_name_category, os.W_OK):\n",
        "        synset_url = 'https://raw.githubusercontent.com/csailvision/places365/master/categories_places365.txt'\n",
        "        os.system('wget ' + synset_url)\n",
        "    classes = list()\n",
        "    with open(file_name_category) as class_file:\n",
        "        for line in class_file:\n",
        "            classes.append(line.strip().split(' ')[0][3:])\n",
        "    classes = tuple(classes)\n",
        "\n",
        "  \n",
        "\n",
        "    # scene attribute relevant\n",
        "    file_name_attribute = 'labels_sunattribute.txt'\n",
        "    if not os.access(file_name_attribute, os.W_OK):\n",
        "        synset_url = 'https://raw.githubusercontent.com/csailvision/places365/master/labels_sunattribute.txt'\n",
        "        os.system('wget ' + synset_url)\n",
        "    with open(file_name_attribute) as f:\n",
        "        lines = f.readlines()\n",
        "        labels_attribute = [item.rstrip() for item in lines]\n",
        "    file_name_W = 'W_sceneattribute_wideresnet18.npy'\n",
        "    if not os.access(file_name_W, os.W_OK):\n",
        "        synset_url = 'http://places2.csail.mit.edu/models_places365/W_sceneattribute_wideresnet18.npy'\n",
        "        os.system('wget ' + synset_url)\n",
        "    W_attribute = np.load(file_name_W)\n",
        "\n",
        "    return classes, labels_attribute, W_attribute\n",
        "\n",
        "def hook_feature(module, input, output):\n",
        "    features_blobs.append(np.squeeze(output.data.cpu().numpy()))\n",
        "\n",
        "def returnCAM(feature_conv, weight_softmax, class_idx):\n",
        "    # generate the class activation maps upsample to 256x256\n",
        "    size_upsample = (256, 256)\n",
        "    nc, h, w = feature_conv.shape\n",
        "    output_cam = []\n",
        "    for idx in class_idx:\n",
        "        cam = weight_softmax[class_idx].dot(feature_conv.reshape((nc, h*w)))\n",
        "        cam = cam.reshape(h, w)\n",
        "        cam = cam - np.min(cam)\n",
        "        cam_img = cam / np.max(cam)\n",
        "        cam_img = np.uint8(255 * cam_img)\n",
        "        output_cam.append(cv2.resize(cam_img, size_upsample))\n",
        "    return output_cam\n",
        "\n",
        "def returnTF():\n",
        "# load the image transformer\n",
        "    tf = trn.Compose([\n",
        "        trn.Resize((224,224)),\n",
        "        trn.ToTensor(),\n",
        "        trn.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    return tf\n",
        "\n",
        "\n",
        "def load_model():\n",
        "    # this model has a last conv feature map as 14x14\n",
        "\n",
        "    model_file = 'wideresnet18_places365.pth.tar'\n",
        "    if not os.access(model_file, os.W_OK):\n",
        "        os.system('wget http://places2.csail.mit.edu/models_places365/' + model_file)\n",
        "        os.system('wget https://raw.githubusercontent.com/csailvision/places365/master/wideresnet.py')\n",
        "\n",
        "    import wideresnet\n",
        "    model = wideresnet.resnet18(num_classes=365)\n",
        "    checkpoint = torch.load(model_file, map_location=lambda storage, loc: storage)\n",
        "    state_dict = {str.replace(k,'module.',''): v for k,v in checkpoint['state_dict'].items()}\n",
        "    model.load_state_dict(state_dict)\n",
        "    \n",
        "    for i, (name, module) in enumerate(model._modules.items()):\n",
        "        module = recursion_change_bn(model)\n",
        "    model.avgpool = torch.nn.AvgPool2d(kernel_size=14, stride=1, padding=0)\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    # hook the feature extractor\n",
        "    features_names = ['layer4','avgpool'] # this is the last conv layer of the resnet\n",
        "    for name in features_names:\n",
        "        model._modules.get(name).register_forward_hook(hook_feature)\n",
        "    return model\n",
        "\n",
        "\n",
        "# load the labels\n",
        "classes, labels_attribute, W_attribute = load_labels()\n",
        "\n",
        "# load the model\n",
        "features_blobs = []\n",
        "model = load_model()\n",
        "\n",
        "# load the transformer\n",
        "tf = returnTF() # image transformer\n",
        "\n",
        "# get the softmax weight\n",
        "params = list(model.parameters())\n",
        "weight_softmax = params[-2].data.numpy()\n",
        "weight_softmax[weight_softmax<0] = 0\n"
      ],
      "metadata": {
        "id": "wEzoZFmYSOqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs(\"heatmaps\")\n",
        "os.makedirs(\"heatmaps/office\")\n",
        "os.makedirs(\"heatmaps/kitchen\")\n",
        "\n",
        "def read_image_from_url(img_url):\n",
        "    img = io.imread(img_url)  #numpy.ndarray\n",
        "    img = Image.fromarray(img) #PIL Image   image_from_array.show()\n",
        "    return img"
      ],
      "metadata": {
        "id": "t8YnsSfElNPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify (img_url):\n",
        "  image =read_image_from_url(img_url)\n",
        "  input_img = V(tf(image).unsqueeze(0))\n",
        "\n",
        "  # forward pass\n",
        "  logit = model.forward(input_img)\n",
        "  h_x = F.softmax(logit, 1).data.squeeze()\n",
        "  probs, idx = h_x.sort(0, True)\n",
        "  probs = probs.numpy()\n",
        "  idx = idx.numpy()\n",
        "  # output the prediction of scene category\n",
        "  print('--SCENE CATEGORIES:')\n",
        "  for i in range(0, 5):\n",
        "      print('{:.3f} -> {}'.format(probs[i], classes[idx[i]]))\n",
        "\n",
        "  # output the scene attributes\n",
        "  responses_attribute = W_attribute.dot(features_blobs[1])\n",
        "  idx_a = np.argsort(responses_attribute)\n",
        "  print('--SCENE ATTRIBUTES:')\n",
        "  print(', '.join([labels_attribute[idx_a[i]] for i in range(-1,-10,-1)]))\n",
        "  # generate class activation mapping\n",
        "\n",
        "  #print('Class activation map is saved in \"heatmaps/'+cat+'/heatmap_' + str(j) +'.jpg\"')\n",
        "  CAMs = returnCAM(features_blobs[0], weight_softmax, [idx[0]])\n",
        "\n",
        "  # render the CAM and output\n",
        "  #img = cv2.imread('test.jpg')\n",
        "  imgs = io.imread(img_url)\n",
        "  height, width, _ = imgs.shape\n",
        "  heatmap = cv2.applyColorMap(cv2.resize(CAMs[0],(width, height)), cv2.COLORMAP_JET)\n",
        "  result = heatmap * 0.4 + imgs * 0.5\n",
        "\n",
        "  imagepath = './heatmaps/'+cat+ '/heatmap_' + str(j) +'.jpg'\n",
        "  cv2.imwrite(imagepath, result)\n",
        "  return imagepath"
      ],
      "metadata": {
        "id": "aJh9MTyL2yNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Όπως φαίνεται και από τα heatmaps που πορκείπτουν από το gradcam "
      ],
      "metadata": {
        "id": "sGvUZ7pu6KwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.image as mpimg\n",
        "for cat in ['kitchen','office']:\n",
        "  print(cat)\n",
        "  for j in range(25):\n",
        "    img_url = img[cat][j]['coco_url']\n",
        "    print(\"Image %s_%d\" %(cat,j) )\n",
        "    print('Annotations', anns_per_image[cat][img[cat][j]['id']]['label_texts'])\n",
        "    heatpath = classify(img_url)\n",
        "    print(heatpath)\n",
        "    print('RESULT ON ' + img_url)\n",
        "    image = read_image_from_url( img_url )\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    # Image.open(imagepath).show()\n",
        "    #display.Image(imagepath)\n",
        "    img_heatmap = mpimg.imread(heatpath)\n",
        "    plt.subplot(1, 2, 2) # index 2\n",
        "    plt.imshow(img_heatmap)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "5etw3AZYi9Q5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for cat in ['kitchen']:#,'office']:\n",
        "  print(cat)\n",
        "  for j in range(25,31):\n",
        "    img_url = img[cat][j]['coco_url']\n",
        "    print(\"Image %s_%d\" %(cat,j) )\n",
        "    print('Annotations', anns_per_image[cat][img[cat][j]['id']]['label_texts'])\n",
        "    heatpath = classify(img_url)\n",
        "    print(heatpath)\n",
        "    print('RESULT ON ' + img_url)\n",
        "    image = read_image_from_url( img_url )\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    # Image.open(imagepath).show()\n",
        "    #display.Image(imagepath)\n",
        "    img_heatmap = mpimg.imread(heatpath)\n",
        "    plt.subplot(1, 2, 2) # index 2\n",
        "    plt.imshow(img_heatmap)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "DFgSxkrt6-l2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uR8BZlg-8R4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_classification(imgCat, imageId):\n",
        "  for ii in img[imgCat]:\n",
        "    if ii['id'] == imageId :\n",
        "      img_url = ii['coco_url']\n",
        "      print(img_url)\n",
        "      print('Annotations', anns_per_image[imgCat][ii['id']]['label_texts'])\n",
        "      heatpath = classify(img_url)\n",
        "      print(\"printed heatpath\")\n",
        "      print(heatpath)\n",
        "      print('RESULT ON ' + img_url)\n",
        "      image = read_image_from_url( img_url )\n",
        "      plt.subplot(1, 2, 1)\n",
        "      plt.imshow(image)\n",
        "      plt.axis('off')\n",
        "      img_heatmap = mpimg.imread(heatpath)\n",
        "      plt.subplot(1, 2, 2) # index 2\n",
        "      plt.imshow(img_heatmap)\n",
        "      plt.axis('off')\n",
        "      plt.show()"
      ],
      "metadata": {
        "id": "vDB9tLBBfI8a"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for cat in ['office']:#,'office']:\n",
        "  print(cat)\n",
        "  for j in range(61):\n",
        "    img_url = img[cat][j]['coco_url']\n",
        "    print(\"Image %s_%d\" %(cat,j) )\n",
        "    print('Annotations', anns_per_image[cat][img[cat][j]['id']]['label_texts'])\n",
        "    heatpath = classify(img_url)\n",
        "    print(heatpath)\n",
        "    print('RESULT ON ' + img_url)\n",
        "    image = read_image_from_url( img_url )\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    # Image.open(imagepath).show()\n",
        "    #display.Image(imagepath)\n",
        "    img_heatmap = mpimg.imread(heatpath)\n",
        "    plt.subplot(1, 2, 2) # index 2\n",
        "    plt.imshow(img_heatmap)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "upRQL6D48Xr-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTAMvyquMCNM"
      },
      "source": [
        "# Γνώση και wordnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IchtG7NMCNN",
        "outputId": "d126eae1-f782-4a19-89b8-3eca58a95adf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting owlready2\n",
            "  Downloading Owlready2-0.38.tar.gz (25.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.4 MB 30.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: owlready2\n",
            "  Building wheel for owlready2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for owlready2: filename=Owlready2-0.38-cp37-cp37m-linux_x86_64.whl size=22127111 sha256=8965af865787de8cce018a0b0d5a67f7b6ed46751709b2ee7adf5cb0363d592a\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/48/58/3ea20d69efcb97a26048fbfcce9332412077df80d4ae52365b\n",
            "Successfully built owlready2\n",
            "Installing collected packages: owlready2\n",
            "Successfully installed owlready2-0.38\n"
          ]
        }
      ],
      "source": [
        "!pip install owlready2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdSlGsi2MCNN",
        "outputId": "5ddbe864-4066-4bf8-dc49-a63a06ea2564"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from owlready2 import *\n",
        "from nltk.corpus import wordnet as wn\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCqS8EZaMCNO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b205448-f971-4583-ec7b-9d21f4f4fe21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "[]\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "# print(list(onto.properties()))\n",
        "# print(list(onto.classes()))\n",
        "# print(list(onto.individuals()))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To dataset ενώνεται με το wordnet βρίσκοντας συνώνυμα και υπερκλάσεις του κάθε label που χαρακτηρίζει μια εικόνα. Για την αναπαράσταση αυτής της γνώσης σε .οwl δημιουργούμε μια οντολογία για την κάθε κατηγορία (kitchen και office). Στην κάθε οντολογία υπάρχουν οι κλάσεις *Image* και *DepictedObejct* ως υποκλάσεις της κλάσης *Thing* της οντολογίας. Ορίζεται επίσης ο ρόλος *hasObject* μεταξύ των προαναφερθέντων κλάσεων. Για κάθε εικόνα δημιουργείται ένα στιγμιότυπο (indivindual/instance) τύπου *Image* με αναγνωριστικό το id της εικόνας. Για κάθε αντικείμενο της εικόνας δημιουργούμε στιγμιότυπο τύπου *DepictedObject* και συνδέουμε την εικόνα με αυτό μέσω του ρόλου *hasObject*. Για το πρώτο synset(συνώνυμο) από το wordnet του εκάστοτε αντικειμένου δημιουργούμε μια κλάση όπως και για όλα τα υπερώνυμά του, διατηρώντας την ιεραρχία μεταξύ τους. Το αντικείμενο ορίζεται ως τύπου της κλάσης του synset και κατά συνέπεια ως τύπου όλων των υπερκλάσεων αυτού. "
      ],
      "metadata": {
        "id": "6FEqs9oSjo0I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXLwFGTcMCNO"
      },
      "outputs": [],
      "source": [
        "for i in onto.individuals():\n",
        "    destroy_entity(i)\n",
        "for i in onto.classes():\n",
        "    destroy_entity(i)\n",
        "for i in onto.properties():\n",
        "    destroy_entity(i)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4tGh0uSAMCNP"
      },
      "outputs": [],
      "source": [
        "for cat in  ['office','kitchen' ]:\n",
        "  #create an ontology with the IRI (identifier) \"http://myontology/kitchen\" and \"http://myontology/office\"\n",
        "  ontology = 'http://myontology/'+cat\n",
        "  onto = get_ontology('http://myontology/'+cat)\n",
        "  with onto:\n",
        "    ## Ορισμός εννοιών για εικόνες και αντικείμενα\n",
        "    class Image(Thing): # Image subclass of owl's class Thing\n",
        "      namespace=onto\n",
        "      pass\n",
        "\n",
        "    class DepictedObject(Thing): # DepictedObject subclass of owl's class Thing\n",
        "      namespace=onto\n",
        "      pass\n",
        "\n",
        "  ## Ορισμός ρόλου \"hasObject\" (ποιες εικόνες περιέχουν ποια αντικείμενα)\n",
        "    class hasObject(Image>>DepictedObject):\n",
        "      namespace=onto\n",
        "      pass\n",
        "\n",
        "\n",
        "  ## ids των 100 πρώτων εικόνων\n",
        "  ids = imgIds[cat][:100]\n",
        "  ## Για κάθε εικόνα\n",
        "  for im_id in ids:\n",
        "      ## Δημιουργία individual τύπου \"Image\"\n",
        "      #im = onto['Image'](str(im_id))\n",
        "      im = Image(str(im_id))\n",
        "\n",
        "      ## Για κάθε αντικείμενο στην εικόνα:\n",
        "      for obj_name in anns_per_image[cat][im_id]['label_texts']:\n",
        "          if \" \" in obj_name:\n",
        "              obj_name = obj_name.replace(\" \", \"_\")\n",
        "              \n",
        "          ## Εύρεση πρώτου synset στο wordnet\n",
        "          synsets = wn.synsets(obj_name)\n",
        "          if len(synsets)<1:\n",
        "              continue\n",
        "          \n",
        "          ## Δημιουργία individual τύπου \"Object\"\n",
        "          obj = DepictedObject()\n",
        "\n",
        "          ## Σύνδεση της εικόνας με το αντικείμενο μέσω του ρόλου hasObject\n",
        "          im.hasObject.append(obj)\n",
        "\n",
        "          synset = synsets[0].name()\n",
        "          if (obj_name == \"mouse\"):\n",
        "            synset = 'mouse.n.04'\n",
        "          elif (obj_name == \"microwave\"):\n",
        "            synset = synsets[1].name()\n",
        "          elif (obj_name == \"toaster\"):\n",
        "            synset = synsets[1].name()\n",
        "          ## Αν υπάρχει η αντίστοιχη έννοια στη γνώση\n",
        "          if onto[synset] in onto.classes():\n",
        "\n",
        "              ## Ορίζουμε το αντικείμενο obj ως τύπου \"synset\"\n",
        "              obj.is_a.append(onto[synset])\n",
        "              ## Αν δεν υπάρχει η αντίστοιχη έννοια στη γνώση, την ορίζουμε, μαζί με τις υπερέννοιές της\n",
        "          else:\n",
        "              print(\"hypenymssss\")\n",
        "              ## Εύρεση υπερώνυμων\n",
        "              hyper = lambda s:s.hypernyms()\n",
        "              hypers = [s.name() for s in list(wn.synset(synset).closure(hyper))]\n",
        "              hypers = reversed(hypers)\n",
        "              ## Ορισμός ιεραρχίας εννοιών\n",
        "              father = Thing\n",
        "              for h in hypers:\n",
        "                if onto[h] not in onto.classes():\n",
        "                    with onto:\n",
        "                        cl = types.new_class(h,(father,))\n",
        "                    #father = onto[h]\n",
        "                father = onto[h]\n",
        "              if onto[synset] not in onto.classes():\n",
        "                  with onto:\n",
        "                      cl = types.new_class(synset,(father,))\n",
        "                  if(obj_name == \"microwave\"):\n",
        "                      print(\"First class for microwave with father\" , father)\n",
        "                  ## Ορίζουμε το αντικείμενο obj ως τύπου \"synset\"\n",
        "              with onto:\n",
        "                  if(obj_name == 'microwave'):\n",
        "                    print(\"Microwave is_a\", onto[synset])\n",
        "                  obj.is_a.append(onto[synset])\n",
        "\n",
        "      ## Αποθηκεύουμε την οντολογία\n",
        "      onto.save('myonto_'+cat+'.nt',format='ntriples')\n",
        "      "
      ]
    }
  ]
}